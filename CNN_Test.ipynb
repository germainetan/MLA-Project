{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Creating a CNN from scratch</h1>\n",
    "\n",
    "References:  \n",
    "https://www.tensorflow.org/tutorials/images/cnn  \n",
    "https://www.datacamp.com/tutorial/cnn-tensorflow-python  \n",
    "\n",
    "Convolutional Layers:  \n",
    "https://www.sciencedirect.com/topics/engineering/convolutional-layer#:~:text=2.3.,-1%20Convolutional%20layer&text=A%20convolutional%20layer%20is%20the,and%20creates%20an%20activation%20map.  \n",
    "https://towardsdatascience.com/convolutional-neural-networks-explained-9cc5188c4939  \n",
    "\n",
    "\n",
    "Model:  \n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/Model  \n",
    "https://keras.io/api/layers/convolution_layers/convolution2d/  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Architecture:\n",
    "\n",
    "Input: ? x ? image (Pixel Size)   \n",
    "-> Convolution Layer 1 -> ReLU Activation -> Max Pooling  \n",
    "-> Convolution Layer 2 -> ReLU Activation -> Max Pooling  \n",
    "-> Convolution Layer 3 -> ReLU Activation  \n",
    "-> Flatten -> Fully Connected Layer (Dense Layer) -> ??? Activation -Softmax/ReLU -> Output Layer (16 units)\n",
    "\n",
    "Output Classes:  \n",
    "(0-9) 10  \n",
    "(+-/*()) 6  \n",
    "Total: 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports and dependencies\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# checking tensorflow version\n",
    "print(\"Your tensorflow version is \" + tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_images(train_images, class_names,train_labels, nb_samples = 12, nb_row = 4):\n",
    "\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    for i in range(nb_samples):\n",
    "        plt.subplot(nb_row, nb_row, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
    "        plt.xlabel(class_names[train_labels[i][0]])\n",
    "    plt.show()\n",
    "\n",
    "class_names = ['0','1','2','3','4','5','6','7','8','9', '+', '-', '*', '/' , '(' , ')']\n",
    "show_images(train_images, class_names,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing \n",
    "\n",
    "# normalise pixel values\n",
    "# TODO: Check if this is necessary, supposedly helps with scale invariance and faster convergence\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yanwe\\Anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 13, 13, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 5, 5, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 3, 3, 128)         73856     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1152)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               147584    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                2064      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 242320 (946.56 KB)\n",
      "Trainable params: 242320 (946.56 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model Architecture Implementation\n",
    "\n",
    "from keras import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "'''\n",
    "Layer Variables - \n",
    "? x ? image (Pixel Size) -> \n",
    "Convolution Layer 1 -> ReLU Activation -> Pooling -> \n",
    "Convolution Layer 2 -> ReLU Activation -> Pooling -> \n",
    "Convolution Layer 3 -> ReLU Activation -> Flatten -> \n",
    "Fully Connected Layer (Dense Layer) -> ??? Activation -Softmax/ReLU -> Output Layer (14 units)\n",
    "'''\n",
    "\n",
    "# decision point: how many layers do we want to implement?\n",
    "input_shape = (28,28,1) # decision point: what size are our images fixed at\n",
    "layer1_size = 32 # number of filters in the convolutional layer\n",
    "layer2_size = 64\n",
    "layer3_size = 128\n",
    "layer_shape = (3,3) # size of the filter\n",
    "\n",
    "pool_shape = (2,2) # size of the pooling laye\n",
    "fully_connected_layer_size = 128 # number of neurons in the fully connected layer\n",
    "num_classes = 16 # number of classes in the output layer\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(layer1_size, layer_shape, activation='relu', input_shape=input_shape)) # decision point: What kind of activation functions to use? ReLU\n",
    "model.add(MaxPooling2D(pool_shape)) # decision points: what kind of pooling function? max, average, global average\n",
    "model.add(Conv2D(layer2_size, layer_shape, activation='relu')) \n",
    "model.add(MaxPooling2D(pool_shape))\n",
    "model.add(Conv2D(layer3_size, layer_shape, activation='relu')) # decision point: to pool one more time or not\n",
    "model.add(Flatten())\n",
    "model.add(Dense(fully_connected_layer_size, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import metrics\n",
    "\n",
    "batch_size = 128 #decision point: optimal batch size?\n",
    "epochs = 10 # decision point: optimal number of epochs?\n",
    "\n",
    "model_metrics = ['accuracy', metrics.Recall(name = \"Recall\"), metrics.Precision(name = \"Precision\")] \n",
    "# decision point: what metrics to use to evaluate the model?\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=model_metrics)\n",
    "# decision point: what loss function to use? what optimizer? what is the learning rate?\n",
    "\n",
    "#train model\n",
    "training_history = model.fit(train_images, train_labels, batch_size=batch_size, epochs=epochs, validation_data=(test_images, test_labels))\n",
    "\n",
    "# END OF MODELLING PROCESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation\n",
    "\n",
    "# Plotting the training and validation loss\n",
    "# Confusion Matrix\n",
    "# Precision, Recall, F1 Score\n",
    "# Performance curves\n",
    "# Check if model under/overfits\n",
    "\n",
    "# Fine-tune different hyperparameters i.e. learning rate, batch size, number of layers etc. to improve model performance\n",
    "# Can consider adding regularization techniques - dropout, L1/L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "test_predictions = model.predict(test_images)\n",
    "\n",
    "test_predicted_labels = np.argmax(test_predictions, axis=1)\n",
    "\n",
    "test_true_labels = np.argmax(test_labels, axis=1)\n",
    "\n",
    "cm = confusion_matrix(test_true_labels, test_predicted_labels)\n",
    "\n",
    "cmd = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "\n",
    "cmd.plot(include_values=True, cmap='viridis', ax=None, xticks_rotation='horizontal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project Solution Flow:\n",
    "\n",
    "Bounding Box codes -> Images -> CNN -> return predicted values -> evaluate with metrics\n",
    "\n",
    "solving function -> Convert the predicted values into a string and use eval() to solve the equation\n",
    "\n",
    "TODO:  \n",
    "Load datasets into GPU Cluster  \n",
    "Load model notebook into GPU Cluster"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
