{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Variable (Edit Before you Run on your own)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS_SIZE = 30 #Adjusted for trial first\n",
    "BATCH_SIZE = 128\n",
    "MODEL_SAVE_NAME = \"digit_symbol_model_v2_with_30epochs\" #change this so that u dont overwrite saved model\n",
    "LOADED_MODEL_NAME = \"\" #Edit this one below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre requisites that you need to install before use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Just Run Once\n",
    "!pip install tensorflow\n",
    "!pip install scikit-learn\n",
    "!pip install keras\n",
    "!pip install keras-tuner\n",
    "!pip install matplotlib\n",
    "!pip install opencv-python\n",
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras_tuner as kt\n",
    "import seaborn as sns\n",
    "from keras import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading The Picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing_from_dir(dataset_dir, class_labels_dict, training=False):\n",
    "    # Initialize lists to store images and labels\n",
    "    images = []\n",
    "    labels = []\n",
    "    class_labels = []\n",
    "\n",
    "    # Get a list of all subdirectories (each subdirectory represents a class)\n",
    "    class_directories = os.listdir(dataset_dir)\n",
    "\n",
    "    # Iterate through each subdirectory (class directory)\n",
    "    for class_directory in class_directories:\n",
    "        class_label = class_directory  # Use the directory name as the class label\n",
    "        \n",
    "        class_labels.append(class_label)\n",
    "        class_path = os.path.join(dataset_dir, class_directory)\n",
    "\n",
    "        # Get a list of image files in the class directory\n",
    "        image_files = glob.glob(os.path.join(class_path, \"*.jpg\"))  # You may need to adjust the file extension\n",
    "\n",
    "        # print(image_files)\n",
    "\n",
    "        # Iterate through image files in the class directory\n",
    "        for image_file in image_files:\n",
    "            # Load and preprocess the image\n",
    "            image = cv2.imread(image_file, cv2.IMREAD_GRAYSCALE)\n",
    "            image = cv2.resize(image, (28, 28))\n",
    "            image = image / 255.0  # Normalize pixel values\n",
    "\n",
    "            # plt.imshow(image, cmap=plt.cm.binary)\n",
    "\n",
    "            # Append the preprocessed image and its label to the lists\n",
    "            images.append(image)\n",
    "            labels.append(class_label)\n",
    "\n",
    "    if training:\n",
    "\n",
    "        data = list(zip(images, labels))\n",
    "\n",
    "        # Shuffle the combined data\n",
    "        np.random.shuffle(data)\n",
    "\n",
    "        # shuffle the training images\n",
    "        shuffled_images, shuffled_labels = zip(*data)\n",
    "\n",
    "        images = np.array(shuffled_images)\n",
    "\n",
    "        label_encoder = LabelEncoder()\n",
    "\n",
    "        # Encode class labels using LabelEncoder\n",
    "        labels = label_encoder.fit_transform(shuffled_labels)\n",
    "\n",
    "        for i in range(len(class_labels)):\n",
    "            class_labels_dict[class_labels[i]] = i\n",
    "\n",
    "        labels = np.array(labels, dtype=\"int64\")\n",
    "\n",
    "        # comment the below 2 lines if doing label-encoding\n",
    "        # One-hot encode labels (need to do one code in order to fit into the model)\n",
    "        num_classes = len(class_labels)\n",
    "        labels = to_categorical(labels, num_classes=num_classes)\n",
    "\n",
    "        return images, labels, class_labels, class_labels_dict\n",
    "\n",
    "    else:\n",
    "       \n",
    "        # Convert lists to NumPy arrays\n",
    "        images = np.array(images)\n",
    "\n",
    "        # label-encoding done on test data should correspond to the ones in training data\n",
    "        # this is to account for times when test data is lesser than training data\n",
    "\n",
    "        for i in range(len(labels)):\n",
    "            labels[i] = class_labels_dict[labels[i]]\n",
    "\n",
    "        labels = np.array(labels, dtype=\"int64\")\n",
    "\n",
    "        # comment the below 2 lines if doing label-encoding\n",
    "        # One-hot encode labels (need to do one code in order to fit into the model)\n",
    "        num_classes = len(class_labels_dict)\n",
    "        labels = to_categorical(labels, num_classes=num_classes)\n",
    "\n",
    "        return images, labels, class_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels, training_class_labels, class_labels_dict = pre_processing_from_dir(\"final_82/train_images\", {}, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation on Training Data \n",
    "- random rotation\n",
    "- random noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augmentation(image):\n",
    "\n",
    "    ##############################################################\n",
    "    # Rotating images to mimic slanted handwriting\n",
    "\n",
    "    # Convert the image to a NumPy array (assuming it's in the range [0, 1])\n",
    "    image = (image * 255).astype(np.uint8)\n",
    "\n",
    "    # Calculate the image center\n",
    "    center = tuple(np.array(image.shape[1::-1]) / 2)\n",
    "\n",
    "    rotation_angle = random.uniform(-30, 30)\n",
    "\n",
    "    # Create a rotation matrix and apply the rotation\n",
    "    rotation_matrix = cv2.getRotationMatrix2D(center, rotation_angle, 1.0)\n",
    "    rotated_image = cv2.warpAffine(image, rotation_matrix, image.shape[1::-1], flags=cv2.INTER_LINEAR, borderValue=(255, 255, 255))\n",
    "\n",
    "    # Convert back to the range [0, 1]\n",
    "    rotated_image = rotated_image.astype(np.float32) / 255.0\n",
    "\n",
    "    ##############################################################\n",
    "    # Adding random noise to mimic low quality images\n",
    "\n",
    "    max_noise_level = random.uniform(0, 0.1)\n",
    "    noise = tf.random.normal(shape=tf.shape(rotated_image), stddev=max_noise_level)\n",
    "    \n",
    "    return tf.clip_by_value(rotated_image + noise, 0.0, 1.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Defining The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import callbacks\n",
    "\n",
    "#Define callback functions. Change model_name, patience, as needed.\n",
    "# keras_callbacks   = [\n",
    "#       callbacks.EarlyStopping(monitor='val_loss', patience=15, mode='min', min_delta=0.0001),\n",
    "#       callbacks.ModelCheckpoint('model_name', monitor='val_loss', save_best_only=True, mode='min')\n",
    "\n",
    "def math_model(images, labels, num_classes, model_name):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    # perform data augmentation on X_train\n",
    "    X_train = np.array([data_augmentation(image) for image in X_train])\n",
    "\n",
    "    # Define your CNN model for multi-class classification\n",
    "\n",
    "    input_shape = (28,28,1) # decision point: what size are our images fixed at\n",
    "    layer1_size = 32 # number of filters in the convolutional layer\n",
    "    layer2_size = 64\n",
    "    layer3_size = 128\n",
    "    layer_shape = (3,3) # size of the filter\n",
    "\n",
    "    pool_shape = (2,2) # size of the pooling laye\n",
    "    fully_connected_layer_size = 128 # number of neurons in the fully connected layer\n",
    "\n",
    "\n",
    "    model = Sequential([\n",
    "        layers.Conv2D(layer1_size, layer_shape, activation='relu', input_shape=input_shape),\n",
    "        layers.MaxPooling2D(pool_shape),\n",
    "        layers.Conv2D(layer2_size, layer_shape, activation='relu'),\n",
    "        layers.MaxPooling2D(pool_shape),\n",
    "        layers.Conv2D(layer3_size, layer_shape, activation='relu'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(fully_connected_layer_size, activation='relu'),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model_metrics = ['accuracy', metrics.Recall(name = \"Recall\"), metrics.Precision(name = \"Precision\")]\n",
    "\n",
    "    # Compile the model\n",
    "    # for one-hot encoding\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=model_metrics)\n",
    "\n",
    "    # uncomment this if using label-encoding, & comment the one above\n",
    "    # model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=model_metrics)\n",
    "\n",
    "    # Fit model. (Batch size either 32, 64, 128. 1000 epochs as we expect training to stop before that.\n",
    "    history = model.fit(X_train, y_train, batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS_SIZE, validation_data=(X_test, y_test))\n",
    "\n",
    "    # Save the trained model for later use\n",
    "    model.save(f\"{model_name}.keras\")\n",
    "\n",
    "    # not a must to return history here but it's to see whether model is overfitting or underfitting after training\n",
    "    # can remove history once we confirmed model is good\n",
    "    return f\"{model_name}.keras\", history, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def math_reports(model, X_test, y_test, test_class_labels, train_class_labels):\n",
    "\n",
    "    # Load the saved model\n",
    "    loaded_model = load_model(model)\n",
    "\n",
    "    predicted_y = loaded_model.predict(X_test)\n",
    "\n",
    "    # Convert one-hot encoded labels back to integer labels\n",
    "    y_test_labels = y_test\n",
    "\n",
    "    # comment this if label-encoding was used\n",
    "    y_test_labels = np.argmax(y_test_labels, axis=1)\n",
    "\n",
    "    predicted_labels = np.argmax(predicted_y, axis=1)\n",
    "\n",
    "    confusion = confusion_matrix(y_test_labels, predicted_labels)\n",
    "\n",
    "    # print(\"Confusion Matrix\")\n",
    "    # print(confusion)\n",
    "    # print()\n",
    "\n",
    "    cf_report = classification_report(y_test_labels, predicted_labels, labels=np.unique(y_test_labels), target_names=test_class_labels)\n",
    "\n",
    "    # print(\"Classification Report\")\n",
    "    # print(cf_report)\n",
    "\n",
    "\n",
    "    # print(\"Confusion Matrix Report\")\n",
    "    # Initialize dictionaries to store correct and total counts for each class\n",
    "    correct_instances_per_class = {}\n",
    "    total_instances_per_class = {}\n",
    "    report = \"\"\n",
    "    predicted_report = \"\"\n",
    "\n",
    "    # Iterate through predictions and true labels to calculate correct and total instances\n",
    "    for i in range(predicted_labels.size):\n",
    "        predicted = train_class_labels[predicted_labels[i]]\n",
    "        test_label = train_class_labels[y_test_labels[i]]\n",
    "\n",
    "        result = \"wrong\"\n",
    "\n",
    "        if (predicted == test_label):\n",
    "            result = \"correct\"\n",
    "\n",
    "        predicted_report += f\"Predicted: {predicted}, Actual: {test_label}, Result: {result}\\n\"\n",
    "\n",
    "        if test_label not in correct_instances_per_class:\n",
    "            correct_instances_per_class[test_label] = 0\n",
    "            total_instances_per_class[test_label] = 0\n",
    "\n",
    "        total_instances_per_class[test_label] += 1\n",
    "\n",
    "        if predicted == test_label:\n",
    "            correct_instances_per_class[test_label] += 1\n",
    "\n",
    "    # print(predicted_report)\n",
    "\n",
    "    import operator\n",
    "\n",
    "    sorted_correct = dict(sorted(correct_instances_per_class.items(), key=operator.itemgetter(0)))\n",
    "\n",
    "    # Print the summary of correct/total for each class\n",
    "    for label in sorted_correct:\n",
    "        correct_count = sorted_correct[label]\n",
    "        total_count = total_instances_per_class[label]\n",
    "        report += f\"Class {label}: Correct {correct_count}/{total_count} | Wrong: {total_count - correct_count}\\n\"\n",
    "\n",
    "    # print(report)\n",
    "\n",
    "    return confusion, cf_report, report, predicted_report, predicted_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1121/1121 [==============================] - 52s 46ms/step - loss: 0.6755 - accuracy: 0.7920 - Recall: 0.7263 - Precision: 0.9003 - val_loss: 0.2443 - val_accuracy: 0.9259 - val_Recall: 0.9175 - val_Precision: 0.9370\n",
      "Epoch 2/30\n",
      "1121/1121 [==============================] - 51s 46ms/step - loss: 0.2469 - accuracy: 0.9242 - Recall: 0.9116 - Precision: 0.9390 - val_loss: 0.1511 - val_accuracy: 0.9558 - val_Recall: 0.9532 - val_Precision: 0.9595\n",
      "Epoch 3/30\n",
      "1121/1121 [==============================] - 50s 45ms/step - loss: 0.1815 - accuracy: 0.9442 - Recall: 0.9372 - Precision: 0.9519 - val_loss: 0.1240 - val_accuracy: 0.9631 - val_Recall: 0.9616 - val_Precision: 0.9654\n",
      "Epoch 4/30\n",
      "1121/1121 [==============================] - 50s 45ms/step - loss: 0.1481 - accuracy: 0.9536 - Recall: 0.9489 - Precision: 0.9592 - val_loss: 0.1357 - val_accuracy: 0.9569 - val_Recall: 0.9548 - val_Precision: 0.9600\n",
      "Epoch 5/30\n",
      "1121/1121 [==============================] - 50s 45ms/step - loss: 0.1291 - accuracy: 0.9592 - Recall: 0.9554 - Precision: 0.9631 - val_loss: 0.1161 - val_accuracy: 0.9650 - val_Recall: 0.9635 - val_Precision: 0.9670\n",
      "Epoch 6/30\n",
      "1121/1121 [==============================] - 50s 44ms/step - loss: 0.1129 - accuracy: 0.9642 - Recall: 0.9615 - Precision: 0.9672 - val_loss: 0.0965 - val_accuracy: 0.9710 - val_Recall: 0.9704 - val_Precision: 0.9724\n",
      "Epoch 7/30\n",
      "1121/1121 [==============================] - 49s 44ms/step - loss: 0.1028 - accuracy: 0.9667 - Recall: 0.9645 - Precision: 0.9695 - val_loss: 0.1072 - val_accuracy: 0.9644 - val_Recall: 0.9632 - val_Precision: 0.9660\n",
      "Epoch 8/30\n",
      "1121/1121 [==============================] - 49s 43ms/step - loss: 0.0933 - accuracy: 0.9702 - Recall: 0.9684 - Precision: 0.9724 - val_loss: 0.1120 - val_accuracy: 0.9657 - val_Recall: 0.9649 - val_Precision: 0.9671\n",
      "Epoch 9/30\n",
      "1121/1121 [==============================] - 48s 43ms/step - loss: 0.0854 - accuracy: 0.9720 - Recall: 0.9705 - Precision: 0.9738 - val_loss: 0.0936 - val_accuracy: 0.9720 - val_Recall: 0.9710 - val_Precision: 0.9727\n",
      "Epoch 10/30\n",
      "1121/1121 [==============================] - 49s 43ms/step - loss: 0.0797 - accuracy: 0.9741 - Recall: 0.9729 - Precision: 0.9756 - val_loss: 0.0929 - val_accuracy: 0.9722 - val_Recall: 0.9716 - val_Precision: 0.9730\n",
      "Epoch 11/30\n",
      "1121/1121 [==============================] - 48s 43ms/step - loss: 0.0736 - accuracy: 0.9757 - Recall: 0.9744 - Precision: 0.9771 - val_loss: 0.0852 - val_accuracy: 0.9741 - val_Recall: 0.9739 - val_Precision: 0.9748\n",
      "Epoch 12/30\n",
      "1121/1121 [==============================] - 49s 43ms/step - loss: 0.0686 - accuracy: 0.9774 - Recall: 0.9764 - Precision: 0.9783 - val_loss: 0.0818 - val_accuracy: 0.9754 - val_Recall: 0.9751 - val_Precision: 0.9759\n",
      "Epoch 13/30\n",
      "1121/1121 [==============================] - 49s 44ms/step - loss: 0.0644 - accuracy: 0.9782 - Recall: 0.9775 - Precision: 0.9791 - val_loss: 0.0807 - val_accuracy: 0.9778 - val_Recall: 0.9771 - val_Precision: 0.9783\n",
      "Epoch 14/30\n",
      "1121/1121 [==============================] - 49s 43ms/step - loss: 0.0600 - accuracy: 0.9800 - Recall: 0.9792 - Precision: 0.9807 - val_loss: 0.0839 - val_accuracy: 0.9750 - val_Recall: 0.9744 - val_Precision: 0.9757\n",
      "Epoch 15/30\n",
      "1121/1121 [==============================] - 49s 44ms/step - loss: 0.0572 - accuracy: 0.9809 - Recall: 0.9803 - Precision: 0.9815 - val_loss: 0.0785 - val_accuracy: 0.9774 - val_Recall: 0.9771 - val_Precision: 0.9779\n",
      "Epoch 16/30\n",
      "1121/1121 [==============================] - 48s 43ms/step - loss: 0.0538 - accuracy: 0.9818 - Recall: 0.9811 - Precision: 0.9825 - val_loss: 0.0782 - val_accuracy: 0.9776 - val_Recall: 0.9771 - val_Precision: 0.9782\n",
      "Epoch 17/30\n",
      "1121/1121 [==============================] - 48s 43ms/step - loss: 0.0516 - accuracy: 0.9821 - Recall: 0.9817 - Precision: 0.9827 - val_loss: 0.0915 - val_accuracy: 0.9747 - val_Recall: 0.9745 - val_Precision: 0.9750\n",
      "Epoch 18/30\n",
      "1121/1121 [==============================] - 48s 43ms/step - loss: 0.0485 - accuracy: 0.9834 - Recall: 0.9830 - Precision: 0.9839 - val_loss: 0.0868 - val_accuracy: 0.9758 - val_Recall: 0.9755 - val_Precision: 0.9765\n",
      "Epoch 19/30\n",
      "1121/1121 [==============================] - 49s 44ms/step - loss: 0.0475 - accuracy: 0.9833 - Recall: 0.9830 - Precision: 0.9838 - val_loss: 0.0936 - val_accuracy: 0.9746 - val_Recall: 0.9743 - val_Precision: 0.9751\n",
      "Epoch 20/30\n",
      "1121/1121 [==============================] - 50s 45ms/step - loss: 0.0452 - accuracy: 0.9844 - Recall: 0.9841 - Precision: 0.9848 - val_loss: 0.0958 - val_accuracy: 0.9745 - val_Recall: 0.9740 - val_Precision: 0.9750\n",
      "Epoch 21/30\n",
      "1121/1121 [==============================] - 51s 45ms/step - loss: 0.0443 - accuracy: 0.9846 - Recall: 0.9843 - Precision: 0.9850 - val_loss: 0.0872 - val_accuracy: 0.9764 - val_Recall: 0.9762 - val_Precision: 0.9767\n",
      "Epoch 22/30\n",
      "1121/1121 [==============================] - 48s 43ms/step - loss: 0.0417 - accuracy: 0.9853 - Recall: 0.9850 - Precision: 0.9857 - val_loss: 0.0903 - val_accuracy: 0.9751 - val_Recall: 0.9748 - val_Precision: 0.9756\n",
      "Epoch 23/30\n",
      "1121/1121 [==============================] - 50s 44ms/step - loss: 0.0416 - accuracy: 0.9855 - Recall: 0.9852 - Precision: 0.9857 - val_loss: 0.0876 - val_accuracy: 0.9765 - val_Recall: 0.9763 - val_Precision: 0.9768\n",
      "Epoch 24/30\n",
      "1121/1121 [==============================] - 50s 44ms/step - loss: 0.0396 - accuracy: 0.9862 - Recall: 0.9859 - Precision: 0.9866 - val_loss: 0.1114 - val_accuracy: 0.9714 - val_Recall: 0.9711 - val_Precision: 0.9721\n",
      "Epoch 25/30\n",
      "1121/1121 [==============================] - 50s 45ms/step - loss: 0.0384 - accuracy: 0.9868 - Recall: 0.9866 - Precision: 0.9870 - val_loss: 0.0965 - val_accuracy: 0.9759 - val_Recall: 0.9757 - val_Precision: 0.9761\n",
      "Epoch 26/30\n",
      "1121/1121 [==============================] - 49s 44ms/step - loss: 0.0381 - accuracy: 0.9864 - Recall: 0.9862 - Precision: 0.9867 - val_loss: 0.0978 - val_accuracy: 0.9751 - val_Recall: 0.9750 - val_Precision: 0.9755\n",
      "Epoch 27/30\n",
      "1121/1121 [==============================] - 49s 44ms/step - loss: 0.0356 - accuracy: 0.9873 - Recall: 0.9871 - Precision: 0.9875 - val_loss: 0.0879 - val_accuracy: 0.9798 - val_Recall: 0.9795 - val_Precision: 0.9799\n",
      "Epoch 28/30\n",
      "1121/1121 [==============================] - 49s 44ms/step - loss: 0.0366 - accuracy: 0.9867 - Recall: 0.9866 - Precision: 0.9870 - val_loss: 0.1020 - val_accuracy: 0.9771 - val_Recall: 0.9768 - val_Precision: 0.9774\n",
      "Epoch 29/30\n",
      "1121/1121 [==============================] - 49s 44ms/step - loss: 0.0348 - accuracy: 0.9876 - Recall: 0.9875 - Precision: 0.9878 - val_loss: 0.0916 - val_accuracy: 0.9789 - val_Recall: 0.9788 - val_Precision: 0.9790\n",
      "Epoch 30/30\n",
      "1121/1121 [==============================] - 49s 44ms/step - loss: 0.0321 - accuracy: 0.9885 - Recall: 0.9884 - Precision: 0.9887 - val_loss: 0.1151 - val_accuracy: 0.9748 - val_Recall: 0.9747 - val_Precision: 0.9750\n"
     ]
    }
   ],
   "source": [
    "model, history, X_test, y_test = math_model(images, labels, len(training_class_labels), MODEL_SAVE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for under/overfitting & deciding on epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOADED_MODEL_NAME = \"\" #change if you want load another model\n",
    "LOADED_MODEL_NAME = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "loaded_model = load_model(LOADED_MODEL_NAME)\n",
    "\n",
    "loss, accuracy = loaded_model.evaluate(X_test, y_test)\n",
    "print(accuracy)\n",
    "print(loss)\n",
    "\n",
    "# Plot the training and validation loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot the training and validation accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion, cf_report, report, predicted_report, predicted_labels = math_reports(model, X_test, y_test, training_class_labels, training_class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion Matrix\")\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification Report\")\n",
    "print(cf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion Matrix Report\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Predicted vs Actual\")\n",
    "print(predicted_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Test Model with Unseen Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'!'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#load test_images\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m images_test, labels_test, test_class_labels \u001b[38;5;241m=\u001b[39m pre_processing_from_dir(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset/test\u001b[39m\u001b[38;5;124m\"\u001b[39m, class_labels_dict)\n",
      "Cell \u001b[1;32mIn[3], line 73\u001b[0m, in \u001b[0;36mpre_processing_from_dir\u001b[1;34m(dataset_dir, class_labels_dict, training)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# label-encoding done on test data should correspond to the ones in training data\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# this is to account for times when test data is lesser than training data\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(labels)):\n\u001b[1;32m---> 73\u001b[0m     labels[i] \u001b[38;5;241m=\u001b[39m class_labels_dict[labels[i]]\n\u001b[0;32m     75\u001b[0m labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(labels, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint64\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# comment the below 2 lines if doing label-encoding\u001b[39;00m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;66;03m# One-hot encode labels (need to do one code in order to fit into the model)\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: '!'"
     ]
    }
   ],
   "source": [
    "#load test_images\n",
    "images_test, labels_test, test_class_labels = pre_processing_from_dir(\"dataset/test\", class_labels_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict using loaded model\n",
    "confusion_test, cf_report_test, report_test, predicted_report_test, predicted_labels_test = math_reports(LOADED_MODEL_NAME, images_test, labels_test, test_class_labels, training_class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification Report Test\")\n",
    "print(cf_report_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion Matrix Test\")\n",
    "print(confusion_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to better visualize confusion matrix\n",
    "\n",
    "# Replace this with your class labels\n",
    "class_labels = [key for key, value in class_labels_dict.items() if value in np.unique(predicted_labels_test)]\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.set(font_scale=1.2)\n",
    "sns.heatmap(confusion_test, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix Heatmap')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion Matrix Report\")\n",
    "print(report_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Predicted vs Actual Test\")\n",
    "print(predicted_report_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## running model with unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing_from_test(dataset_dir):\n",
    "    # Initialize lists to store images and labels\n",
    "    images = []\n",
    "    labels = []\n",
    "    class_labels = []\n",
    "\n",
    "    # Get a list of all subdirectories (each subdirectory represents a class)\n",
    "    class_directories = os.listdir(dataset_dir)\n",
    "\n",
    "    # Iterate through each subdirectory (class directory)\n",
    "    for class_directory in class_directories:\n",
    "        class_label = class_directory  # Use the directory name as the class label\n",
    "        \n",
    "        class_labels.append(class_label)\n",
    "        class_path = os.path.join(dataset_dir, class_directory)\n",
    "\n",
    "        # Get a list of image files in the class directory\n",
    "        image_files = glob.glob(os.path.join(class_path, \"*.png\"))  # You may need to adjust the file extension\n",
    "\n",
    "        # print(image_files)\n",
    "\n",
    "        # Iterate through image files in the class directory\n",
    "        for image_file in image_files:\n",
    "            # Load and preprocess the image\n",
    "            image = cv2.imread(image_file, cv2.IMREAD_GRAYSCALE)\n",
    "            image = cv2.resize(image, (28, 28))\n",
    "            image = image / 255.0  # Normalize pixel values\n",
    "\n",
    "            # plt.imshow(image, cmap=plt.cm.binary)\n",
    "\n",
    "            # Append the preprocessed image and its label to the lists\n",
    "            images.append(image)\n",
    "            labels.append(class_label)\n",
    "\n",
    "    return np.array(images), class_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ez_test, ez_labels = pre_processing_from_test(\"final_82/ez\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 60ms/step\n",
      "predicted_labels:  [ 4 10 12]\n",
      "predicted output:  0 6 8 \n"
     ]
    }
   ],
   "source": [
    "training_class_labels = ['(',')','+','-','0','1','2','3','4','5','6','7','8','9','=','div','times']\n",
    "\n",
    "# Load the saved model\n",
    "model = \"digit_symbol_model_v2_with_30epochs.keras\"\n",
    "\n",
    "loaded_model = tf.keras.saving.load_model(model)\n",
    "#loaded_model = tf.keras.models.load_model(model)\n",
    "\n",
    "predicted_y = loaded_model.predict(ez_test)\n",
    "\n",
    "predicted_labels = np.argmax(predicted_y, axis=1)\n",
    "\n",
    "print(\"predicted_labels: \", predicted_labels)\n",
    "\n",
    "predicted_report = \"\"\n",
    "\n",
    "# Iterate through predictions and true labels to calculate correct and total instances\n",
    "for i in range(predicted_labels.size):\n",
    "    predicted = training_class_labels[predicted_labels[i]]\n",
    "    predicted_report += predicted + \" \"\n",
    "\n",
    "print(\"predicted output: \", predicted_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate with ground Truth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>gt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20_em_41</td>\n",
       "      <td>9/5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RIT_2014_29</td>\n",
       "      <td>- 7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RIT_2014_70</td>\n",
       "      <td>1 + 1 + 1 + 1 + 1 = 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35_em_15</td>\n",
       "      <td>1 \\times 1 + 1 \\times 2 + 2 \\times 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RIT_2014_284</td>\n",
       "      <td>- 39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RIT_2014_299</td>\n",
       "      <td>897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>515_em_351</td>\n",
       "      <td>1 = 1(1)(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RIT_2014_204</td>\n",
       "      <td>47474 + 5272 = 52746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>18_em_21</td>\n",
       "      <td>1011\\ 1110\\ 1110\\ 0101_2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           path                                    gt\n",
       "0      20_em_41                                   9/5\n",
       "1   RIT_2014_29                                  - 7 \n",
       "2   RIT_2014_70                1 + 1 + 1 + 1 + 1 = 5 \n",
       "3      35_em_15  1 \\times 1 + 1 \\times 2 + 2 \\times 2\n",
       "4  RIT_2014_284                                 - 39 \n",
       "5  RIT_2014_299                                  897 \n",
       "6    515_em_351                          1 = 1(1)(1) \n",
       "7  RIT_2014_204                 47474 + 5272 = 52746 \n",
       "8      18_em_21              1011\\ 1110\\ 1110\\ 0101_2"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "filtered_data = pd.read_excel(\"ten_paths.xlsx\")\n",
    "\n",
    "filtered_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the dataframe into dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ez': '1 + 2 ', 'rit_4235_3': ' \\\\frac {5} {6} ', 'rit_4240_0': ' 57753336 ', 'rit_4210_4': ' \\\\frac {9} {7} ', 'rit_4225_2': ' 8 \\\\sqrt {3} ', 'rit_4225_3': ' \\\\frac {56} {8} ', 'rit_4295_0': ' 523 + 487 ', 'rit_4250_3': ' \\\\sqrt {18} ', 'ritm_422_0': ' + 7 \\\\times 9 ^ {5} + 7 \\\\times 9 ^ {4} + 7 \\\\times 9 ^ {3} + 7 \\\\times 9 ^ {2} + 7 \\\\times 9 ', 'rit_42100_2': ' \\\\frac {\\\\sqrt {4}} {2} ', 'rit_420_3': ' 9 ^ {9 ^ {9 ^ {9 ^ {9 ^ {9}}}}} ', 'rit_4230_0': ' \\\\frac {7} {6} ', 'rit_4260_4': ' \\\\frac {1} {8} ', 'rit_4230_2': ' \\\\frac {3} {7} ', 'rit_4250_2': ' \\\\sqrt {28} ', 'rit_4280_0': ' \\\\frac {91} {48} ', 'rit_4265_0': ' 4 ^ {4 ^ {4}} + 3 ', 'rit_4290_4': ' \\\\sqrt {3 + \\\\sqrt {2}} ', 'rit_42190_4': ' \\\\sqrt {- 1} \\\\times \\\\sqrt {- 1} ', 'rit_4245_3': ' 7 \\\\sqrt {7} - 3 \\\\sqrt {3} ', 'rit_42100_3': ' \\\\frac {2 \\\\pm \\\\sqrt {2}} {4} ', 'rit_4275_2': ' \\\\frac {3} {4} ', 'rit_4235_0': ' \\\\frac {7} {5} ', 'rit_4230_3': ' \\\\frac {6} {3} ', 'rit_4235_2': ' 6 \\\\frac {\\\\sqrt {3}} {4} ', 'rit_4295_1': ' \\\\sqrt {5 + 2 \\\\sqrt {6}} ', 'rit_42150_0': ' 3 ^ {3 ^ {3}} + 3 ', '127_em_508': '2S+1', '120_em_300': '(2)', 'rit_42130_0': ' \\\\frac {5} {3} ', 'rit_4260_1': ' \\\\frac {8 \\\\sqrt {2}} {3} ', 'rit_4280_2': ' \\\\sqrt {\\\\sqrt {2}} ', 'rit_4225_4': ' 7 ^ {7 ^ {7}} ', 'rit_42190_3': ' \\\\sqrt {1 + \\\\frac {1} {\\\\sqrt {2}}} + \\\\sqrt {1 - \\\\frac {1} {\\\\sqrt {2}}} ', 'rit_4215_3': ' \\\\frac {9} {5} ', 'rit_4235_4': ' \\\\frac {\\\\sqrt {3}} {3} ', 'rit_4245_2': ' 6 + 3 \\\\sqrt {3} ', 'rit_42160_2': ' \\\\pm \\\\sqrt {- 1} ', 'rit_4240_4': ' \\\\frac {\\\\sqrt {3}} {4} ', 'rit_4220_1': ' 9 \\\\times 9 ', 'rit_4220_3': ' \\\\frac {9} {4} ', 'rit_4240_3': ' 4 \\\\sqrt {3} ', 'rit_42110_2': ' \\\\sqrt {14} ', 'RIT_2014_61': ' 0.0878 ', 'RIT_2014_247': ' 1 \\\\pm \\\\sqrt {2} ', '23_em_55': '\\\\sqrt{113}', '23_em_60': '\\\\frac{2}{3} + \\\\frac{1}{9} = (\\\\frac{7}{9})', '508_em_86': '\\\\sqrt{45} = \\\\sqrt{ 9 \\\\times 5} = 3 \\\\sqrt{5}', '511_em_251': ' \\\\frac{3}{7} - \\\\frac{2}{7} = \\\\frac{1}{7}', 'RIT_2014_251': ' \\\\frac {\\\\sqrt {6} + \\\\sqrt {2}} {4} ', 'RIT_2014_131': ' \\\\sqrt {91} ', 'RIT_2014_51': ' 1, 000 _ {}, 000 _ {}, 000 ', 'RIT_2014_239': ' \\\\frac {z ^ {- 1} (1 + z ^ {- 1})} {(1 - z ^ {- 1}) ^ {3}} ', '504_em_44': '8_{16}', 'RIT_2014_57': ' 19 ', '20_em_41': '9/5', 'RIT_2014_29': ' - 7 ', '512_em_287': '{{\\\\sqrt{17}}\\\\div{\\\\sqrt{5}}}', '515_em_359': '(4/3,2/3,4/3)', '512_em_291': '2.9999', 'RIT_2014_156': ' - 1 ', 'RIT_2014_95': ' 20 ', '513_em_311': '10^\\\\frac{1}{10}', 'RIT_2014_302': ' \\\\pm \\\\sqrt {\\\\frac {15} {16}} ', 'RIT_2014_258': ' \\\\frac {1} {2} \\\\frac {1} {4} \\\\frac {1} {8} \\\\frac {1} {16} ', '517_em_413': '\\\\frac{9 + 3\\\\sqrt{65}}{-56}', '18_em_23': '\\\\frac{18 \\\\div 6}{24 \\\\div 6} = \\\\frac{3}{4}', '510_em_105': '\\\\frac{4}{3}', '31_em_196': '\\\\frac{3 + 9 + 7 + 3 + 6 + 10 + 4}{7} = 6', '20_em_42': '17', 'RIT_2014_41': ' - \\\\sqrt {3} ', '37_em_5': '\\\\frac{\\\\sqrt{2+\\\\sqrt{2}}}{2}', '517_em_409': '1(1) = (1)( \\\\frac{1}{1} )', 'RIT_2014_234': ' \\\\frac {1 - \\\\sqrt {3}} {1 + \\\\sqrt {3}} ', 'RIT_2014_248': ' \\\\frac {2 - p} {\\\\sqrt {1 - p}} ', 'RIT_2014_281': ' 100, 000 ', '32_em_217': '\\\\sqrt{-1}', '502_em_0': '63', '518_em_438': '\\\\frac{2}{\\\\sqrt{2-\\\\sqrt{2}}}', 'RIT_2014_130': ' 8 - 7 ', '18_em_1': '\\\\sqrt{48} ', 'RIT_2014_85': ' \\\\frac {56 \\\\div 7} {63 \\\\div 7} = \\\\frac {8} {9} ', '36_em_31': '\\\\frac{\\\\sqrt{162}}{\\\\sqrt{200}}', 'RIT_2014_138': ' \\\\frac {\\\\frac {\\\\sqrt {3}} {2}} {\\\\frac {1} {2}} = \\\\sqrt {3} ', 'RIT_2014_280': ' \\\\sqrt {9} + \\\\sqrt {16} ', 'RIT_2014_97': ' 12 ', '516_em_389': ' 92.08553692\\\\ldots \\\\ ', '518_em_430': '\\\\frac{4+4+4}{4}', 'RIT_2014_99': ' \\\\frac {1} {9} ', 'RIT_2014_70': ' 1 + 1 + 1 + 1 + 1 = 5 ', 'RIT_2014_88': ' \\\\frac {4 + 4} {4 + 4} ', '502_em_2': '492', '512_em_298': '\\\\frac{1}{5} + \\\\frac{3}{5} = \\\\frac{1+3}{5} = \\\\frac{4}{5}', '28_em_142': '\\\\frac{44467}{38973}', '501_em_1': '{\\\\sqrt{50}}', '519_em_440': '\\\\frac{8993}{7873}', '505_em_47': '\\\\ 5 + 3 = (1 + 1 + 1 + 1 + 1) + (1 + 1 +1)  = 8', 'RIT_2014_122': ' 18 z ', '35_em_20': '\\\\sqrt{38}', '35_em_15': '1 \\\\times 1 + 1 \\\\times 2 + 2 \\\\times 2', '518_em_427': '{\\\\sqrt{7}+\\\\sqrt{28}}', '505_em_49': '{1\\\\sqrt{7}+2\\\\sqrt{7}}', '26_em_97': '\\\\sqrt{-4} = \\\\sqrt{-1}\\\\sqrt{4}', '501_em_15': '\\\\frac{29302}{75803} = \\\\frac{7\\\\times 7\\\\times 13\\\\times 46} {7\\\\times 7\\\\times 13\\\\times 119} = \\\\frac{46}{119} ', 'RIT_2014_189': ' \\\\sqrt {648 + 648} ABOVE {4} + 8 ', '20_em_43': '(648+648)^\\\\frac{1}{4}+8', '509_em_90': '\\\\pm\\\\sqrt{6}', 'RIT_2014_108': ' \\\\frac {2 ^ {2} + 7} {2 ^ {5} 7 ^ {2}} ', '18_em_24': '\\\\frac{7529536}{15625}', '516_em_399': '\\\\frac{3}{8}', 'RIT_2014_152': ' 44 - \\\\frac {4} {4} ', '27_em_118': '\\\\sqrt{32} + \\\\sqrt{32}', '507_em_77': '\\\\sqrt[3]{(2)(9)(12)} = \\\\sqrt[3]{216} = 6', '26_em_78': '169', '36_em_34': '\\\\sqrt{2}\\\\sqrt{2} = 2', '27_em_120': '{\\\\sqrt{15}}', '36_em_49': '1.6946961', 'RIT_2014_210': ' \\\\frac {1} {4} + \\\\frac {2} {5} = \\\\frac {1 \\\\times 5} {4 \\\\times 5} + \\\\frac {2 \\\\times 4} {5 \\\\times 4} = \\\\frac {5} {20} + \\\\frac {8} {20} ', '512_em_289': '\\\\frac{1}{8}', '512_em_284': ' (6)(6)(6) = 216 ', 'RIT_2014_284': ' - 39 ', '515_em_354': '4\\\\sqrt{3}', '37_em_19': '-\\\\frac{\\\\sqrt{2-\\\\sqrt{2}}}{2}', '35_em_6': '{15} \\\\div {5} = 3', 'RIT_2014_299': ' 897 ', '507_em_76': '4\\\\times4+4+4 \\\\!', '519_em_448': '\\\\left (  \\\\left ( \\\\frac{1}{4} \\\\left ( 3 \\\\right )^4 - 3 \\\\left ( 3 \\\\right )^2 \\\\right ) - \\\\left ( \\\\frac{1}{4} \\\\left ( 2 \\\\right )^4 - 3 \\\\left ( 2 \\\\right )^2 \\\\right )  \\\\right )', '29_em_159': '18', '514_em_335': '\\\\frac{\\\\sqrt{2-\\\\sqrt{2}}}{2}', '36_em_28': '12 \\\\div 3', '28_em_125': '\\\\frac{2}{\\\\sqrt{2+\\\\sqrt{2}}}', 'RIT_2014_73': ' \\\\{ 7, 7 \\\\} = \\\\{ 7 \\\\} ', '516_em_376': '2^{-4}', '515_em_351': '1 = 1(1)(1) ', '36_em_39': '\\\\frac{(3)(3+1)}{2} = 6 = 1 + 2 + 3', '28_em_133': '3=\\\\frac{3}{2}(3^1-1)=3', '31_em_187': '50', '35_em_19': '2\\\\div3', '18_em_21': '1011\\\\ 1110\\\\ 1110\\\\ 0101_2', 'RIT_2014_204': ' 47474 + 5272 = 52746 ', '18_em_10': '26', '26_em_99': '\\\\ 10,000 + 1,000 = 11,000', '512_em_278': '\\\\sqrt{75}', '26_em_93': '4\\\\times4+4-4 \\\\!', '510_em_101': '\\\\frac{6 \\\\div 2}{10 \\\\div 2} = \\\\frac{3}{5}', 'RIT_2014_28': ' \\\\sqrt {\\\\frac {5} {4}} = \\\\frac {\\\\sqrt {5}} {\\\\sqrt {4}} = \\\\frac {\\\\sqrt {5}} {2} ', 'RIT_2014_231': ' 3 \\\\sqrt {7} ', 'RIT_2014_257': ' \\\\frac {11} {3} \\\\sqrt {3} ', 'RIT_2014_307': ' \\\\sqrt {98} ', '501_em_5': '{\\\\sqrt{50}}', '34_em_227': '6588', '29_em_150': '{60}^o\\\\!', '27_em_100': '\\\\sqrt{45}', '512_em_280': '3.00000003', '518_em_420': '\\\\frac{3 \\\\div 3}{9 \\\\div 3} = \\\\frac{1}{3}', '31_em_195': '1 \\\\times 2 \\\\times 3 \\\\times 4 \\\\times 5 \\\\times 6 = 720', 'RIT_2014_39': ' \\\\sqrt {- 4} ', '504_em_36': '\\\\frac{112 \\\\div 2}{126 \\\\div 2} = \\\\frac{56}{63}', '513_em_310': '8 + 7', 'RIT_2014_273': ' \\\\frac {1} {3} + \\\\frac {2} {3} = \\\\frac {3} {3} ', '518_em_428': '1110\\\\ 0011_2', '519_em_447': ' \\\\frac{252 - 2}{5} ', '18_em_13': '4^2+4^2+\\\\frac{4}{4}', '28_em_146': '\\\\frac{199}{11}', 'RIT_2014_272': ' 40 ', '20_em_26': '\\\\frac{9}{9 + \\\\sqrt{9}}', '516_em_380': '4 + 4 - 4 + {\\\\sqrt4}', '508_em_85': '9.8', '506_em_57': '\\\\frac{4}{4}+\\\\frac{4}{4}', '23_em_57': '\\\\sqrt{3^2+2^2}=\\\\sqrt{13}', '511_em_254': '(-1)^3 - 1 = -1 - 1 = -2', '504_em_39': '\\\\frac{\\\\sqrt{27}}{\\\\sqrt[3]{9}}', '37_em_16': '8\\\\sqrt{5}', '502_em_18': '9{\\\\sqrt{2}}', 'RIT_2014_120': ' \\\\sqrt {67} ', 'RIT_2014_279': ' 4 - 4 + 4 - \\\\sqrt {4} ', 'RIT_2014_254': ' \\\\frac {1} {2} \\\\div \\\\frac {3} {4} ', 'RIT_2014_246': ' 7588 ', '20_em_47': '5395', '23_em_56': '9 + 2', '37_em_20': '0.9 - 0.9 = 0', '20_em_28': '1.379194171', '502_em_23': '0+0+0+0+0+0 = 0', '23_em_53': '\\\\frac{1}{3} + \\\\frac{1}{3}', '27_em_110': '(29)-2(16)+(3)=29-32+3=0', '26_em_96': '4+4+\\\\frac{4}{4}', 'RIT_2014_22': ' 3.00000001 ', '517_em_405': '4 + 4 +\\\\frac{4}{\\\\sqrt4}', '27_em_119': '6778', '26_em_80': '\\\\frac{319}{28}=11.39', 'RIT_2014_224': ' \\\\pm \\\\frac {0.05} {50} = \\\\pm 0.001 ', '35_em_0': '299\\\\ 792\\\\ 458', 'UN_133_em_1117': '8\\\\times 8', 'UN_133_em_1125': '\\\\frac{4}{135}\\\\sqrt{5}', 'UN_120_em_437': '-\\\\frac{1}{2},-\\\\frac{1}{2},+\\\\frac{1}{2},+\\\\frac{1}{2}', 'UN_110_em_229': '8=2+2+1+1+1+1', 'UN_464_em_940': '(0 , \\\\frac {1}{ 10} , \\\\frac {3}{ 5} , \\\\frac {3}{ 2} , \\\\frac {7}{ 16} , \\\\frac {3}{ 80})', 'UN_129_em_1044': '-\\\\frac{9920}{99}', 'UN_119_em_409': '\\\\sqrt{2(2+\\\\sqrt{2})}', 'UN_107_em_169': '\\\\frac{2}{\\\\sqrt{3}} - \\\\frac{1}{2\\\\sqrt{3}} = \\\\frac{1}{2\\\\sqrt{3}} - (-\\\\frac{1}{\\\\sqrt{3}})= \\\\frac{\\\\sqrt{3}}{2}', 'UN_104_em_75': '\\\\frac{\\\\sqrt{1517}}{13}', 'UN_456_em_736': '\\\\frac{-29+\\\\sqrt{1517}}{26}', 'UN_133_em_1128': '3.1.3', 'UN_452_em_645': '-\\\\frac{4}{24}-\\\\frac{4}{16}=-\\\\frac{5}{12}', 'UN_110_em_235': '\\\\sqrt{3+\\\\sqrt{3}} \\\\sqrt{3-\\\\sqrt{3}}=\\\\sqrt{3} \\\\sqrt{2}', 'UN_451_em_613': '-\\\\left(\\\\frac{5+\\\\sqrt{5}}{5-\\\\sqrt{5}} \\\\right)^{\\\\frac{1}{4}}', 'UN_462_em_889': '-\\\\frac{4\\\\sqrt{3}-2}{11}', 'UN_465_em_969': '7{\\\\times}7', 'UN_458_em_796': '+2(7+8-8+8-8)', 'UN_464_em_935': '-0.73 \\\\div 0.54', 'UN_451_em_618': '-2^{\\\\frac{1}{4}}\\\\left(\\\\frac{5-\\\\sqrt{5}}{5+\\\\sqrt{5}} \\\\right)^{\\\\frac{3}{4}}', 'UN_108_em_188': '0.7771', 'UN_134_em_1146': '199 \\\\times 199', 'UN_110_em_227': '8+7+7+4=26', 'UN_101_em_10': '\\\\frac{1}{4}=-\\\\frac{3}{4}+1', 'UN_457_em_766': '1+16+120+10=147', 'UN_105_em_112': '\\\\pm \\\\sqrt{-1}', 'UN_127_em_590': '\\\\sqrt{\\\\frac{1}{3}}', 'UN_454_em_695': '3.8', 'UN_117_em_357': '1 + 4 + 6 + 4 + 1 = 16', 'UN_451_em_603': '2^{-\\\\frac{1}{9}}3^{-\\\\frac{1}{3}}', 'UN_104_em_98': '8,393 398 582', 'UN_466_em_983': '-\\\\frac {1}{ 2}\\\\pm \\\\sqrt{H\\\\left(s+\\\\frac {1}{ 2}\\\\right)+4}', 'UN_453_em_665': '\\\\frac {5}{ 8}', 'UN_124_em_530': '1.8\\\\times 1.6', 'UN_114_em_304': '+1-1+1-1+1=+1', 'UN_125_em_555': '-\\\\sqrt{2(2+\\\\sqrt{2})}', 'UN_460_em_847': '9\\\\times 9', 'UN_461_em_858': '7\\\\times 7', 'UN_122_em_492': 'q= \\\\frac{\\\\sqrt{d}}{2}', 'UN_123_em_500': '-\\\\frac { 1}{3}+1=-\\\\frac { 2}{3}', 'UN_131_em_1088': '2.4\\\\times 1.2', 'UN_133_em_1116': '\\\\pm\\\\sqrt{3}', 'UN_128_em_1016': '-(2b-96) = 2b-96-192', 'UN_119_em_400': '6\\\\times6', 'UN_112_em_283': '(9+1)-(5+5)-(1+9)', 'UN_460_em_831': '7+7', 'UN_456_em_734': '696 729 600', 'UN_102_em_32': '(3.1.5)', 'UN_466_em_984': '\\\\frac{9-4\\\\sqrt{3}}{33}', 'UN_454_em_697': '(10+2)-(6+6)-(2+10)', 'UN_464_em_947': '[2] [3] = [2] + [4]', 'UN_125_em_559': '10\\\\div30', 'UN_120_em_428': '(33)^3(73)', 'UN_112_em_273': '\\\\left(\\\\frac{5-\\\\sqrt{5}}{5+\\\\sqrt{5}} \\\\right)^{\\\\frac{3}{4}}', 'UN_461_em_866': '4 = 1+1+1+1', 'UN_462_em_883': '\\\\frac{9+4\\\\sqrt{3}}{33}', 'UN_108_em_181': '\\\\sqrt 3 (\\\\sqrt 2)', 'UN_118_em_385': '8 \\\\times 8 \\\\times 28', 'UN_464_em_929': '1_{1}+1_{2}+1_{3}+3_{1}+3_{2}', 'UN_105_em_119': '\\\\sqrt 7+1', 'UN_466_em_981': '\\\\frac{1}{16}, \\\\frac{1}{16},\\\\frac{1}{16},\\\\frac{9}{16}', 'UN_459_em_800': '-\\\\frac{1}{24} \\\\times \\\\frac { 8}{3} \\\\times 3 \\\\times 2 \\\\times 6 =-4', 'UN_451_em_620': '+ 2 (- 2)', 'UN_113_em_287': '-\\\\sqrt{2-\\\\sqrt{2}}', 'UN_455_em_707': '\\\\frac{7}{16}+9', 'UN_118_em_386': '-0.988', 'UN_109_em_212': '5 \\\\times 5 \\\\times\\\\ldots \\\\times 5', 'UN_465_em_972': '\\\\frac{1}{\\\\sqrt{3}}', 'UN_130_em_1071': '\\\\frac{9}{8}', 'UN_120_em_426': '\\\\frac { 9}{4}', 'UN_117_em_351': '-19.9469', 'UN_459_em_802': '(1+\\\\sqrt{7})', 'UN_109_em_209': '-\\\\frac{1}{2\\\\sqrt{3}}', 'UN_452_em_625': '-0.901,-0.960, -0.979', 'UN_123_em_507': '6+6', 'UN_117_em_352': '2+1+1+1=2+(1+1+1)=3+2', 'UN_107_em_157': '\\\\sqrt{3\\\\pm\\\\sqrt{3}}', 'UN_131_em_1079': '\\\\lim q_{n}=\\\\alpha', 'UN_456_em_733': '- 1 \\\\div 3', 'UN_466_em_999': '\\\\frac{9}{5}', 'UN_460_em_834': '0.54 \\\\div 1.28', 'UN_460_em_830': '\\\\sqrt{\\\\frac{11}{10}}', 'UN_103_em_73': '\\\\frac{-11+\\\\sqrt{221}}{10}', 'UN_463_em_922': '\\\\frac{1}{2}+\\\\frac{1}{2}= 1', 'UN_114_em_299': '- \\\\frac {7}{480} \\\\sqrt{30}', 'UN_131_em_1082': '\\\\frac {0}{0}', 'UN_101_em_5': '-8.8\\\\times 10^{+7}', 'UN_106_em_143': '2[(\\\\frac { 1}{2} ,0) + (0,\\\\frac { 1}{2})]', 'UN_130_em_1072': 'xz = e^u+e^v+e^{-t-u+v}+1', 'UN_458_em_784': '9+9', 'UN_117_em_346': '1 \\\\div 10', 'UN_458_em_788': '\\\\frac{1}{2\\\\sqrt{2-\\\\sqrt{3}}}', 'UN_455_em_716': '8.0777', 'UN_460_em_836': '\\\\sigma\\\\sigma\\\\sigma', 'UN_455_em_718': '(\\\\frac{1}{18},\\\\frac{1}{18})', 'UN_131_em_1078': '\\\\log|\\\\sin q|', 'UN_121_em_460': '(\\\\frac { 8}{9},\\\\frac { 8}{9})', 'UN_131_em_1076': '[a(a+b)cdc(a+b)a]', 'UN_134_em_1145': '\\\\sqrt{3+\\\\sqrt{3}}', 'UN_457_em_772': '(\\\\frac{1}{8},\\\\frac{1}{8})', 'UN_107_em_174': '-\\\\frac {247}{3840} \\\\sqrt{30}', 'UN_124_em_542': '-\\\\frac{7}{675}\\\\sqrt{5}', 'UN_117_em_353': '\\\\frac{7}{16}+7', 'UN_453_em_671': 'q^\\\\frac {1}{2}-q^{-\\\\frac {1}{2}}', 'UN_452_em_641': '\\\\sqrt{2+\\\\sqrt{2}}', 'UN_129_em_1030': '\\\\frac{2.5}{\\\\sqrt{2}}', 'UN_131_em_1083': '[e]', 'UN_113_em_285': '- \\\\frac {1}{160} \\\\sqrt{30}', 'UN_111_em_259': '4+7+7+1+1=20', 'UN_125_em_564': '30 \\\\div 35', 'UN_130_em_1073': 'P_m', 'UN_462_em_885': '-\\\\frac{1}{2},+\\\\frac{1}{2},-\\\\frac{1}{2},+\\\\frac{1}{2}', 'UN_456_em_738': '8+8', 'UN_461_em_861': '1.923-4.134s+1.653s^3', 'UN_461_em_859': '(q^{\\\\frac {1}{ 2}}-q^{-\\\\frac {1}{ 2}})^{-2}', 'UN_466_em_985': '16\\\\times 2\\\\times 2-(16+16\\\\times 2)=16', 'UN_131_em_1080': '-99', 'UN_452_em_628': '\\\\frac{7}{16}+6', 'UN_123_em_509': '\\\\frac {7}{ 9}', 'UN_119_em_395': '-\\\\sqrt{2(2-\\\\sqrt{2})}', 'UN_459_em_818': '\\\\frac {7}{1440} \\\\sqrt{30}', 'UN_102_em_27': '(\\\\frac{1}{9},\\\\frac{1}{9})', 'UN_453_em_650': '1 \\\\div 3', 'UN_128_em_1003': '6+6+16=28', 'UN_131_em_1075': '\\\\int dx^1 dx^2', 'UN_105_em_109': '1^2+1^2+1^2 + 3^2 + 2^2 + 2^2 + 2^2', 'UN_131_em_1099': '-\\\\frac{992}{99}', 'UN_119_em_402': '\\\\frac {16}{3 \\\\sqrt{3}}', 'UN_125_em_567': '2^{\\\\frac{1}{4}}\\\\left(\\\\frac{5+\\\\sqrt{5}}{5-\\\\sqrt{5}} \\\\right)^{\\\\frac{1}{4}}', 'UN_464_em_944': '-\\\\sqrt{3}', 'UN_119_em_413': '\\\\frac{7}{6}', 'UN_124_em_531': '3.14', 'UN_123_em_495': '-\\\\frac{4}{16}+\\\\frac{4}{24}=-\\\\frac{1}{12}', 'UN_108_em_199': '+\\\\sqrt{3}', 'UN_112_em_282': '8{\\\\times}8', 'UN_133_em_1130': '(73)(37)(77)', 'UN_454_em_680': '(\\\\frac { 4}{9},\\\\frac { 4}{9})', 'UN_115_em_316': '3\\\\times 1 +3\\\\times 1 = 6', 'UN_104_em_82': '-0,46 \\\\div 1', 'UN_125_em_557': '\\\\sqrt{-1}', 'UN_453_em_666': '5+2+4+4+3=18', 'UN_460_em_837': '\\\\frac{243}{154}=\\\\frac{3}{2}+\\\\frac{6}{77}', 'UN_457_em_756': '- \\\\frac{13}{8} + \\\\frac{9}{4} + \\\\frac{1}{24} = \\\\frac{2}{3}', 'UN_463_em_915': '1_{1}+1_{2}+1_{3}+1_{4}+3\\\\times 4', 'UN_131_em_1085': '\\\\frac {4}{ 9}', 'UN_130_em_1074': 'B_n=\\\\frac{n}{n-2}B_{n-1}', 'UN_455_em_706': '(2.7.1)', 'UN_131_em_1081': 'r=z \\\\tan{\\\\alpha}', 'UN_110_em_247': '(-\\\\frac{1}{3}, -\\\\frac{1}{3},-\\\\frac{1}{3},-\\\\frac{1}{3},-\\\\frac{1}{3},\\\\frac{4}{3},\\\\frac{2}{3},\\\\frac{2}{3})', 'UN_128_em_1013': '-9\\\\sqrt 7', 'UN_109_em_224': '\\\\frac{1}{\\\\sqrt{b}}', 'UN_108_em_193': '\\\\pm\\\\frac {1}{ 6}', 'UN_125_em_558': '\\\\int L_0', 'UN_131_em_1086': '-\\\\sqrt{2+\\\\sqrt{2}}', 'UN_456_em_737': '[-0.6617,0.6617]', 'UN_131_em_1077': 'x_ax_a', 'UN_121_em_467': '0 \\\\div 4', 'UN_131_em_1084': '- \\\\frac {7}{160} \\\\sqrt{30}', 'UN_464_em_945': '-\\\\frac { 1}{3}+\\\\frac { 1}{2}=\\\\frac { 1}{6}', 'UN_460_em_840': '- \\\\frac {1}{180} \\\\sqrt{30}', 'UN_456_em_741': '-999', 'UN_127_em_597': '9\\\\mbox{x}9'}\n"
     ]
    }
   ],
   "source": [
    "filtered_data_dictionary = filtered_data.set_index('path')['gt'].to_dict()\n",
    "print(filtered_data_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Predicted Labels collect all symbols also convert them to gt notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_all_predict(predict_labels):\n",
    "    line = \"\"\n",
    "    for i in range(predicted_labels.size):\n",
    "        predicted = training_class_labels[predicted_labels[i]]\n",
    "        line += convert_into_gt(predicted) + \" \"\n",
    "        \n",
    "    return line\n",
    "\n",
    "def convert_into_gt(input_symbol):\n",
    "    symbols =['(',')','+','-','0','1','2','3','4','5','6','7','8','9','=','div','times']\n",
    "    \n",
    "    if input_symbol == 'div':\n",
    "        return \"/div\"\n",
    "    if input_symbol == 'times':\n",
    "        return \"/times\"\n",
    "    return input_symbol\n",
    "    ## in gt symbals div are /div and times are /times\n",
    "    \n",
    "combine = combine_all_predict(predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 6 8 \n"
     ]
    }
   ],
   "source": [
    "print(combine)\n",
    "def compare_w_ground(path,combined_predicted):\n",
    "    ground_truth = filtered_data_dictionary.get(path)\n",
    "    return string_similarity(combined_predicted,ground_truth)\n",
    "\n",
    "def string_similarity(str1, str2):\n",
    "    # Remove white spaces from both strings\n",
    "    str1 = str1.replace(\" \", \"\")\n",
    "    str2 = str2.replace(\" \", \"\")\n",
    "    \n",
    "    # Calculate the length of the longer string\n",
    "    max_length = max(len(str1), len(str2))\n",
    "    \n",
    "    # Initialize a variable to count the number of matching characters\n",
    "    matching_count = 0\n",
    "    \n",
    "    # Compare the characters of both strings\n",
    "    for char1, char2 in zip(str1, str2):\n",
    "        if char1 == char2:\n",
    "            matching_count += 1\n",
    "    \n",
    "    # Calculate the percentage of similarity\n",
    "    similarity_percentage = (matching_count / max_length) * 100\n",
    "    \n",
    "    return similarity_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(compare_w_ground('ez',combine))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Into Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
